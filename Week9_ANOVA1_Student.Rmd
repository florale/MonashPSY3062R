---
title: "Week 9 - One-way ANOVA"
author: "Your Name"
date: "`r Sys.Date()`"
output: html_document
---
# Intro

This week we learn how to conduct one-way analysis of variance (ANOVA), 
including checking assumptions, fitting model, and running post-hoc analyses.

# Packages

```{r pkg, message=FALSE}
library(data.table)
library(psych)
library(car)
library(ggplot2)
library(JWileymisc)
library(extraoperators)
library(lm.beta)
library(visreg)
library(olsrr)
library(corrplot)
library(ggsci)
library(emmeans)
```

New packages to get effect sizes and conduct homogeneity corrections for ANOVA models.

```{r, message=FALSE}
install.packages("effectsize")
install.packages("onewaytests")

library(effectsize)
library(onewaytests)
```

# Data

```{r}
d <- fread("week7_dataset.csv")
```

**Research Questions**
We are going to use ANOVA to address the following question: 
* Does Alcohol Consumption have an influence on Variable1?

## Data management
**Exercise**
Check data types of the two main variables. 


```{r}

```

We can see that `AUDITCat` is not a factor yet. This happens often with factor variables in `R` and 
we have to manually convert them.

**Exercise**

Convert `AUDITCat` to a factor using either `factor()` or `as.factor()` function.

```{r}

```

Check data type again to make sure it works.

```{r}
class(d$AUDITCat)
```

# Descriptive Statistics

**Exercise**
Check descriptive statistics using `egltable()`. 

```{r}

```


We may be interested in the descriptive of our variables, separated by groups. 
We can do this by adding an argument `g` to `egltable()`.

```{r}
egltable(c("Variable1"), g = "AUDITCat", data = d)
```

# ANOVA Model
We can use `aov()` function to fit an ANOVA model. The model syntax is the same as a `lm` model.

```{r}
m <- aov(Variable1 ~ AUDITCat, data = d)
summary(m)
```

Alternatively, recall that ANOVA model is also a regression. Therefore, we can also fit our model using 
the `lm()` function and use the `Anova()` function from the `car` package to obtain relevant ANOVA statistics. 

```{r}
lmm <- lm(Variable1 ~ AUDITCat, data = d)
summary(lmm)
```

Our `lm` model gives output like how we fit a model with categorical predictor 
using dummy coding. It will give you tests of individual groups against the reference groups, 
but won't give us a test of the factor as a whole. 
However, we still can obtain a ANOVA table for this model.

```{r}
Anova(lmm)
```

You can see that the output from the `aov` model and `Anova` model are the same. 
Both tell us whether there is a group difference in the outcome 
(1 or more group means are statistically significantly different from each other).

There are advantages of using a LM model.
With this approach, you could basically fit the same model(s) that you would with a ANOVA model, 
with the advantage that LM do not require balanced designs but allows both categorical and continuous predictors 
(e.g., you could include continuous covariates easily) as well as some useful functions for post-hoc analyses.
LMs can do everything that t-tests and various ANOVAs can, but with greater flexibility.

## Assumptions for ANOVA
Assumptions for ANOVA are quite similiar to linear regression (because it is technically a regression).

### Normality of residuals
To check normality of residuals, we can plot standardised residuals using a QQ plot.

```{r}
plot(lmm, 2)
```

### Homogeneity of variance
For Homogeneity of variance, we can either use

* Residual vs predicted plot

```{r}
plot(lmm, 1)
```

* Levene's test

```{r}
leveneTest(Variable1 ~ AUDITCat, data = d)
```

### Homogeneity Corrections
If Homogeneity of variance is violated, we will use either Brown-Forsythe or Welch test.

```{r}
# Brown-Forsythe
bf.test(Variable1 ~ AUDITCat, data = d)

# Welch
welch.test(Variable1 ~ AUDITCat, data = d)
```

### Outliers
We can pretty much use the same methods for regression to check outliers for ANOVA.

## Effect sizes
Eta-squared or omega-squared can be obtained using functions the `effectsize` package. 

```{r}
eta_squared(lmm)
omega_squared(lmm)
```

**Sample Write-up for non-sig ANOVA**
A one-way ANOVA was used to examine the difference in Variable 1 across different levels of alcohol consumption. 
Prior to analysis, assumption of normality was checked using inspection of Q-Q plot of standardized 
residuals and found supported.
Levene’s statistic was non-significant (p = 0.36) indicating that the assumption of homogeneity of
variance was met.
The results were non-significant, showing that Abstainer, Moderate Drinkers, 
and people who are At Risk of alcohol addiction are not different in their level of Variable1
F(2, 377) = 1.31, p = 0.27.

*Notes* : If you did not have a significant ANOVA result, you would stop at this point and just
report the ANOVA result. For learning purposes, we will go ahead with Post Hoc Tests. 

# Pairwise comparison
ANOVA only tells us whether there is a group difference, 
but we don't know which group is different from the other. 
When the result from ANOVA is significant (p < .05),
we can use a follow-up test to find where the differences are.

To conduct follow-up test, we can use the `emmeans` package that works with both `aov` and `lm` models. 

```{r}
em <- emmeans(lmm, pairwise ~ AUDITCat)
```

The default adjustment is TukeyHSD. We can choose another method, 
such as Bonferroni by adding an `adjust = Bonferroni` argument.

```{r}
em_b <- emmeans(lmm, pairwise ~ AUDITCat, adjust = "Bonferroni")
```

Summarise our results. We add `infer= TRUE` argument to show p-values.

* TukeyHSD

```{r}
summary(em, infer = TRUE)
```

* Bonferroni

```{r}
summary(em_b, infer = TRUE)
```

## Cohen's d
Cohen's d is the effect size for the different between two groups. 
It is simply a measure of the distance between two means, measured in standard deviations.
When we have more than two groups, we can use `eff_size()` to calculate 
standardized effect sizes are typically calculated using pairwise differences of estimates.
This funcition takes our `emmeans` model result, along with two arguments, `sigma = sigma(model_name)` 
to specify the Standard Deviation of our model, and `edf = df.residual(model_name)` 
to specify the equivalent degrees of freedom for the `sigma`.

```{r}
eff_size(em, sigma = sigma(lmm), edf = df.residual(lmm))
```

If we only have two groups in our predictor, we can use the `cohen_d()` function 
(this won't work for this model because we have three groups).

```{r}
cohens_d(Variable1 ~ AUDITCat, data = d)
```

# Visualising results
We can use the `visreg` package to graph the results from the `lm` model. 

```{r}
visreg(lmm,
       xvar = "AUDITCat",
       overlay = TRUE, partial = FALSE, band = TRUE, rug = FALSE, gg = TRUE)
```

Alternatively, we can use the `emmip()` function to plot our result. This function takes 
the `emmeans` model result, rather than the `lm` model.

```{r}
emmip(em, ~ AUDITCat, CIs = TRUE) +
  ylab("Variable1") + xlab("Alcohol Consumption")
```


**Sample Write-up for sig ANOVA**
A one-way ANOVA was used to examine the difference in Variable 1 across different levels of alcohol consumption. 
Prior to analysis, assumption of normality was checked using inspection of Q-Q plot of standardized 
residuals and found supported.
Levene’s statistic was non-significant (p = 0.36) indicating that the assumption of homogeneity of
variance was met.
The results were "significant", showing that Abstainer, Moderate Drinkers, 
and people who are At Risk of alcohol addiction are not different in their level of Variable1
F(2, 377) = 1.31, p = 0.27.

Tukey’s post hoc analyses (using an α of .05) revealed that participants in the 
Abstainer group (M = 31.47, SD = 4.57) experienced less Variable1 compared to the At Risk group (M = 32.29, SD = 4.32), 
(b = [95% CI ], p = ), 
with a negative effect d = -0.19. 
Both Abstainer and At Risk groups showed higher level of Variable1 than Moderate (M = 31.17, SD = 4.08) group,
(b = [95% CI ], p = ), and (b = [95% CI ], p = ), respectively.
These were small differences with d = 0.07 and 0.26, respectively.
